[{"uri":"https://jonahjon.github.io/ps-eks-accelerator/getting-started/self_paced/account/","title":"Create an AWS account","tags":[],"description":"","content":" Your account must have the ability to create new IAM roles and scope other IAM permissions.\n   If you don\u0026rsquo;t already have an AWS account with Administrator access: create one now by clicking here\n  Once you have an AWS account, ensure you are following the remaining workshop steps as an IAM user with administrator access to the AWS account: Create a new IAM user to use for the workshop\n  Enter the user details:   Attach the AdministratorAccess IAM Policy:   Click to create the new user:   Take note of the login URL and save:   "},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/getting-started/","title":"Getting Started","tags":["beginner","cicd","security","cloud-native","containers","devsecops"],"description":"","content":"Getting Started   To start the workshop, follow one of the following depending on whether you are\u0026hellip;\n \u0026hellip;running the workshop on your own (in your own account), or \u0026hellip;attending an AWS hosted event (using AWS provided hashes)  Once you have completed with either setup, continue with Create a Workspace\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/configure_environment/","title":"Configure Environment","tags":["beginner","devsecops","devops","cicd","security","containers"],"description":"","content":"Getting Started Once you have completed with either setup, continue with Create a Workspace\nObjectives In this section, we will be focusing on configuring the Workspace for this workshop. It involves the following steps:\n Creating a Cloud9 IDE environment Install Kubernetes tools Setup IAM permissions  "},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/configure_aqua/","title":"Getting Started with Aqua Platform","tags":[],"description":"","content":"Aqua Platform is a complete and comprehensive cloud-native security platform that secures existing workflows and workloads, facilitates regulatory compliance, enforces immutability, and captures security data for forensics. Together, Aqua and Amazon EKS provide a highly controlled environment that greatly reduces the attack surface before your application is even deployed, and automatically detects and responds to anomalies during runtime.\nObjectives In this section, we will set the foundation for the workshop by deploying the Aqua Platform on an Amazon EKS cluster.\n Install the AWS and Aqua tools Create the Amazon EKS cluster Obtain the Aqua license Deploy Aqua platform  Basic Layout Each chapter or folder has to have an \u0026ldquo;_index.md\u0026rdquo; file.\n├── Building\\ Clusters │ ├── _index.md │ ├── eksctl.md │ ├── introduction.md │ └── terraform.md └── _index.md  Ordering files/chapters I add the following at the top of each _index.md file.\ntitle = The name of the chapter on the sidebar\nchapter = determines whether or not it can weighted with other chapters within the same folder. (I set this to true for every markdown file)\n+++ title = \u0026quot;Building Clusters Part 1\u0026quot; date = 2020-06-16T19:01:12-04:00 weight = 5 #weight specifies the order chapter = true pre = \u0026quot;\u0026lt;b\u0026gt;\u0026lt;/b\u0026gt;\u0026quot; +++  If I wanted to add another section called \u0026ldquo;Building Clusters Part 2\u0026rdquo; I would add in a new markdown file \u0026ldquo;part2.md\u0026rdquo;\nAt the top I would add +++ title = \u0026quot;Building Clusters Part 2\u0026quot; date = 2020-06-16T19:01:12-04:00 weight = 10 #weight specifies the order chapter = true pre = \u0026quot;\u0026lt;b\u0026gt;\u0026lt;/b\u0026gt;\u0026quot; +++  Running locally make docs  or\ncd ps-eks-accelerator \u0026amp;\u0026amp; hugo serve -D  navigate to http://localhost:1313/ps-eks-accelerator\nImages Images live in the ps-eks-accelerator/static/images/name-of-chapter/image.png\nAdding an image Examples is to add the image eks-product-page.png in the Chapter Introduction\nWe would add the image to ps-eks-accelerator/static/images/introduction/eks-product-page.png\nLinking to an image in a page ![Example Image](/images/introduction/eks-product-page.png)!  Code samples To add a bash code block use three backticks ```bash (MY CODE HERE) ``` To add a yaml code block use three backticks ```yaml (MY CODE HERE) ```\nCollapse Text #Remove the spaces between the brackets {{ }} { {%expand \u0026quot;Title of the Colapse\u0026quot; %} } Things: to put in my collapase { {% /expand %} }\u0026quot;  Launching Site on Github via Environments Here we show how you use Github to automatically build/deploy this site on Github Pushes and Merges\nStep 1 Create an actions file\ntouch .github/workflows/docs.yaml  Step 2 Change the two parameters in the config.toml to match desired github repo.\n The repo name needs to match the hugo project name If we wanted to rename it we need to change both.  baseurl = \u0026quot;https://jonahjon.github.io/ps-eks-accelerator\u0026quot;  Step 3 Assuming you have, or know how to create a github API key go do that through the developer settings.\nName it ACTIONS_DEPLOY_KEY\nStep 4 Finish by adding in our github actions workflow. This will deploy the site on git pushes, and can be found in the \u0026ldquo;Environments\u0026rdquo; section under the repo.\nname: Publish EKS Accelerator on: push: branches: [ master ] jobs: build: runs-on: ubuntu-latest steps: - uses: actions/checkout@v1 - name: Checkout uses: actions/setup-node@v1 with: node-version: 10.x - name: Setup Hugo uses: peaceiris/actions-hugo@v2.2.1 with: hugo-version: '0.58.3' - name: Prepare Hugo run: | git submodule sync \u0026amp;\u0026amp; git submodule update --init - name: Build run: make docs - name: add nojekyll run: touch ./ps-eks-accelerator/public/.nojekyll - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: publish_dir: ./ps-eks-accelerator/public # default: public github_token: ${{ secrets.GITHUB_TOKEN }}  "},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/configure_aqua/tools/","title":"Installing pre-requisites","tags":[],"description":"","content":"Installing eksctl for managing Amazon EKS curl --silent --location \u0026quot;https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz\u0026quot; | tar xz -C /tmp sudo mv /tmp/eksctl /usr/local/bin eksctl version  Installing aquactl for managing Aqua operations The interactive Aqua Security aquactl command line tool simplifies the deployment of Aqua Platform on a variety of environments, including Amazon EKS.\nwget \u0026quot;https://get.aquasec.com/aquactl/stable/aquactl\u0026quot; chmod +x ./aquactl ./aquactl --help  "},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/devsecops/","title":"Module 1: DevSecOps","tags":[],"description":"","content":"Module 1: DevSecOps DevSecOps, sometimes called security as code, integrates security best practices into a DevOps pipeline instead of bolting them on at the end. It’s a new security paradigm that can evolve with fast-changing security requirements.\nInstrumenting DevSecOps using Aqua and AWS CodePipeline Due to their immutable nature, container workloads are most likely an output of a CI/CD pipeline, where code flows only in one direction: from artifacts to full-fledged workloads running in production. DevSecOps aligns with the Shift Left movement and incorporates Security as a first-class citizen in your DevOps workflows, to uncover security issues at the inception of the application. To help us in this regard, we use AWS CodePipeline. It automates the build, test, and deploy phases of your release process every time there\u0026rsquo;s a code change, based on the release model you define.\nThe build phase is the best time to reduce the attack surface as there is less complexity and interdependency involved. We approach Aqua has the most powerful and accurate scanner out there that weeds out bad configuration, embedded secrets and vulnerabilities with the least number of false positives, making sure that you are starting with a secure foundation right out the gate.\nLearning Objective  Aqua platform architecture Integrating with AWS CodePipeline for scanning artifacts Understand the scan report and remediation advice Deploying clean artifacts to Amazon EKS  "},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/fargate/logging/application/","title":"Application Logging","tags":[],"description":"","content":"Chapter 5 Application Logging Chapter about Application Logging\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/runtime_security/building-clusters/","title":"Building Clusters","tags":[],"description":"","content":"Chapter 1 Building Clusters Chapter about Building Clusters\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/fargate/logging/cluster/","title":"Cluster Logging","tags":[],"description":"","content":"Chapter 5 Cluster Logging Chapter about Cluster Logging\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/security/container-runtime-security/","title":"Container Runtime Security","tags":[],"description":"","content":"Chapter 11 Container Runtime Security Chapter about Container Runtime Security\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/security/container-runtime-security/_example/","title":"Container Runtime Security Examples","tags":[],"description":"","content":"Chapter 11 Examples Container Runtime Security Examples Chapter about Container Runtime Security Examples\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/security/container-runtime-security/_partner/","title":"Container Runtime Security Partners","tags":[],"description":"","content":"Chapter 11 Partners Container Runtime Security Partners Chapter about Container Runtime Security Partners\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/configure_aqua/eks_cluster/","title":"Creating an Amazon EKS cluster","tags":[],"description":"","content":"Amazon Elastic Kubernetes Service (Amazon EKS) is a fully managed Kubernetes service, trusted to run the most sensitive and mission critical applications because of its security, reliability, and scalability.\nEKS Cluster creation eksctl create cluster --name aqua --region ${AWS_REGION} --zones ${AWS_REGION}a,${AWS_REGION}b  Launching EKS and all the dependencies will take approximately 15 minutes\n Verify the cluster Test the cluster: Confirm your nodes:\nkubectl get nodes # if we see our 2 nodes, we know we have authenticated correctly  Export the Worker Role Name for use throughout the workshop: STACK_NAME=$(eksctl get nodegroup --cluster aqua -o json | jq -r '.[].StackName') ROLE_NAME=$(aws cloudformation describe-stack-resources --stack-name $STACK_NAME | jq -r '.StackResources[] | select(.ResourceType==\u0026quot;AWS::IAM::Role\u0026quot;) | .PhysicalResourceId') echo \u0026quot;export ROLE_NAME=${ROLE_NAME}\u0026quot; | tee -a ~/.bash_profile  Congratulations! You now have a fully working Amazon EKS Cluster that is ready to use!\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/runtime_security/eks-cluster-provisioning/","title":"EKS Cluster Provisioning","tags":[],"description":"","content":"Chapter 2 EKS Cluster Provisioning Chapter about EKS Cluster Provisioning\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/runtime_security/eks-cluster-provisioning/_example/","title":"EKS Cluster Provisioning Examples","tags":[],"description":"","content":"Chapter 2 Examples EKS Cluster Provisioning Examples Chapter about EKS Cluster Provisioning Examples\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/runtime_security/eks-cluster-provisioning/_partner/","title":"EKS Cluster Provisioning Partners","tags":[],"description":"","content":"Chapter 2 Partners EKS Cluster Provisioning Partners Chapter about EKS Cluster Provisioning Partners\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/security/encryption-and-secrets-management/","title":"Encryption and Secrets Management","tags":[],"description":"","content":"Chapter 9 Encryption and Secrets Management Chapter about Encryption and Secrets Management\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/security/encryption-and-secrets-management/_example/","title":"Encryption and Secrets Management Examples","tags":[],"description":"","content":"Chapter 9 Examples Encryption and Secrets Management Examples Chapter about Encryption and Secrets Management Examples\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/security/encryption-and-secrets-management/_partner/","title":"Encryption and Secrets Management Partners","tags":[],"description":"","content":"Chapter 9 Partners Encryption and Secrets Management Partners Chapter about Encryption and Secrets Management Partners\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/security/identity-and-access-management/","title":"Identity and Access Management","tags":[],"description":"","content":"Chapter 8 Identity and Access Management Chapter about Identity and Access Management\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/security/identity-and-access-management/_example/","title":"Identity and Access Management Examples","tags":[],"description":"","content":"Chapter 8 Examples Identity and Access Management Examples Chapter about Identity and Access Management Examples\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/security/identity-and-access-management/_partner/","title":"Identity and Access Management Partners","tags":[],"description":"","content":"Chapter 8 Partners Identity and Access Management Partners Chapter about Identity and Access Management Partners\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/fargate/logging/","title":"Logging","tags":[],"description":"","content":"Chapter 5 Logging Chapter about Logging\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/registry_scanning/","title":"Module 2: Secure ECR Registry","tags":[],"description":"","content":"Module 2: Secure ECR Registry Most DevOps and security professionals would agree that it is both important as well as easier to secure containers early in their lifecycle. Aqua “shifts left” the security controls and applies them as part of the CI/CD pipeline - but it is as important to have continuous monitoring of all images to make sure that the production environment is kept secured as time goes by. You can achieve this by integrating Aqua with Amazon ECR via the Integrations tab right from the Aqua Web console.\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/fargate/monitoring/","title":"Monitoring","tags":[],"description":"","content":"Chapter 4 Monitoring Chapter about Monitoring\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/fargate/monitoring/_example/","title":"Monitoring Examples","tags":[],"description":"","content":"Chapter 4 Examples Monitoring Examples Chapter about Monitoring Examples\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/fargate/monitoring/_partner/","title":"Monitoring Partners","tags":[],"description":"","content":"Chapter 4 Partners Monitoring Partners Chapter about Monitoring Partners\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/runtime_security/multi-tenancy-design/","title":"Multi-tenancy design","tags":[],"description":"","content":"Chapter 3 Multi-tenancy design Chapter about Multi-tenancy design\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/runtime_security/multi-tenancy-design/_example/","title":"Multi-tenancy design Examples","tags":[],"description":"","content":"Chapter 3 Examples Multi-tenancy design Examples Chapter about Multi-tenancy design Examples\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/runtime_security/multi-tenancy-design/_partner/","title":"Multi-tenancy design Partners","tags":[],"description":"","content":"Chapter 3 Partners Multi-tenancy design Partners Chapter about Multi-tenancy design Partners\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/security/network-security/","title":"Network Security","tags":[],"description":"","content":"Chapter 10 Network Security Chapter about Network Security\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/security/network-security/_example/","title":"Network Security Examples","tags":[],"description":"","content":"Chapter 10 Examples Network Security Examples Chapter about Network Security Examples\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/security/network-security/_partner/","title":"Network Security Partners","tags":[],"description":"","content":"Chapter 10 Partners Network Security Partners Chapter about Network Security Partners\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/runtime_security/networking-architecture/","title":"Networking Architecture","tags":[],"description":"","content":"Chapter 7 Networking Architecture Chapter about Networking Architecture\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/runtime_security/networking-architecture/_example/","title":"Networking Architecture Examples","tags":[],"description":"","content":"Chapter 7 Examples Networking Architecture Examples Chapter about Networking Architecture Examples\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/runtime_security/networking-architecture/_partner/","title":"Networking Architecture Partners","tags":[],"description":"","content":"Chapter 7 Partners Networking Architecture Partners Chapter about Networking Architecture Partners\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/registry_scanning/ecr-integration/_example/","title":"Pipelines Examples","tags":[],"description":"","content":"Chapter 7 Examples Pipelines Examples Chapter about Pipelines Examples\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/registry_scanning/ecr-integration/_partner/","title":"Pipelines Partners","tags":[],"description":"","content":"Chapter 7 Partners Pipelines Partners Chapter about Pipelines Partners\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/storage/stateful-storage-architecture/","title":"Stateful Storage Architecture","tags":[],"description":"","content":"Chapter 6 Stateful Storage Architecture Chapter about Stateful Storage Architecture\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/storage/stateful-storage-architecture/_example/","title":"Stateful Storage Architecture Examples","tags":[],"description":"","content":"Chapter 6 Examples Stateful Storage Architecture Examples Chapter about Stateful Storage Architecture Examples\nTo download and install the EBS CSI driver\ncurl -O https://raw.githubusercontent.com/kubernetes-sigs/aws-ebs-csi-driver/v0.4.0/docs/example-iam-policy.json aws iam create-policy --policy-name Amazon_EBS_CSI_Driver \\ --policy-document file://example-iam-policy.json kubectl apply -k \u0026quot;github.com/kubernetes-sigs/aws-ebs-csi-driver/deploy/kubernetes/overlays/stable/?ref=master\u0026quot;  "},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/storage/stateful-storage-architecture/_partner/","title":"Stateful Storage Architecture Partners","tags":[],"description":"","content":"Chapter 6 Partners Stateful Storage Architecture Partners Chapter about Stateful Storage Architecture Partners\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/configure_aqua/deploy_aqua/","title":"Deploying Aqua Platform on Amazon EKS","tags":[],"description":"","content":"You can deploy the Aqua Platform application in an existing Amazon EKS cluster in a separate namespace. For easier scaling and high-availability, deploy it in an Amazon EKS cluster of its own in a separate virtual private cloud (VPC).\nCreate an Amazon RDS Postgres database for Aqua Platform Aqua Platform requires a Postgres database to store operational data such as policies, configuration data, and audit events. To provision Amazon RDS with a PostgreSQL engine option, launch this AWS CloudFormation template inside your AWS account.\nDeploy the Amazon RDS database Click the Launch button to create the CloudFormation stack in the AWS Management Console.\n   Launch template       Aqua Postgres DB  Launch    Download      Obtain the RdsInstanceEndpoint in the AWS CloudFormation output, which you will be using in the next step.\nDeploy Aqua Platform on Amazon EKS Go to the AWS Cloud9 IDE and follow the steps in succession.\n./aquactl deploy csp  It’s an interactive command line tool, so it prompts you to enter all the relevant options.\n Respond to the aquactl command-line prompts shown in the figure. These are:\n Aqua license details. Amazon RDS details (including Database IP or DNS URL). Aqua administrator password.  Note the Aqua Console Service endpoint.\nAQUA_ELB=$(kubectl get svc aqua-web --namespace aqua -o jsonpath=\u0026quot;{.status.loadBalancer.ingress[0].hostname}\u0026quot;) AQUA_CONSOLE=\u0026quot;http://$AQUA_ELB:8080\u0026quot; echo $AQUA_CONSOLE  Login to the Aqua Console Open a browser and log in to the Aqua Console using the AQUA_CONSOLE URL from the above output, plus the Aqua administrator password. Once you are logged in, enter the Aqua license token from your Aqua account.\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/runtime_security/","title":"Module 3: Secure the workloads","tags":[],"description":"","content":"Runtime Security for Amazon EKS Workloads with Aqua Cluster Ops Chapter about Cluster Ops\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/configure_aqua/configure_enforcers/","title":"Configuring Enforcers for Aqua Platform","tags":[],"description":"","content":"Aqua takes a policy-driven approach to enforce security for remediation and compliance. To do this effectively, it uses Aqua Enforcers to monitor the runtime activity of containers, collect information about the running workloads, and enforce security based on the policies defined. Aqua provides various types of Enforcers tailored specifically to the different deployment environments.\nAqua Enforcers for Amazon EKS are deployed as a Kubernetes DaemonSet on every cluster worker node to be managed by Aqua. DaemonSets ensure all Amazon EKS cluster nodes run a copy of a pod, and allow Aqua to run a daemon on every node. Enforcement can be applied to containers, hosts, and the network activity between them in the form of firewall policies.\nCheck the status of the Aqua Enforcers in the Aqua Console: Enable additional features and set them to Enforce mode: Congratulations! You have successfully deployed and configured the Aqua Platform!\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/runtime_security/building-clusters/introduction/","title":"Introduction","tags":[],"description":"","content":"Introduction and Background Kubernetess Tools Installation Kubectl The Kubernetes command-line tool, kubectl, allows you to run commands against Kubernetes clusters.\nReqiured Tools for EKS\n Kubectl AWS IAM Authenticator  Install for Linux:   Expand to see Linux Kubectl install Instructions   Download the Kubectl binary:\n#Kubectl curl -LO https://storage.googleapis.com/kubernetes-release/release/`curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt`/bin/linux/amd64/kubectl chmod +x ./kubectl sudo mv ./kubectl /usr/local/bin/kubectl kubectl version --client #AWS IAM Authcenticator curl -o aws-iam-authenticator https://amazon-eks.s3.us-west-2.amazonaws.com/1.16.8/2020-04-16/bin/linux/amd64/aws-iam-authenticator chmod +x ./aws-iam-authenticator mkdir -p $HOME/bin \u0026amp;\u0026amp; cp ./aws-iam-authenticator $HOME/bin/aws-iam-authenticator \u0026amp;\u0026amp; export PATH=$PATH:$HOME/bin echo 'export PATH=$PATH:$HOME/bin' \u0026gt;\u0026gt; ~/.bashrc aws-iam-authenticator help    Install for MacOSx   Expand to see Mac OSX Kubectl install Instructions   Install via Homebrew\n#Kubectl brew install kubectl kubectl version --client #AWS IAM Authcenticator brew install aws-iam-authenticator aws-iam-authenticator help    Install for Windows   Expand to see Windows Kubectl install Instructions   Install via Chocolatey\n#Kubectl choco install kubernetes-cli kubectl version --client #AWS IAM Authcenticator choco install -y aws-iam-authenticator aws-iam-authenticator help    "},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/fargate/logging/application/considerations/","title":"Logging Considerations","tags":[],"description":"","content":"Logging Considerations When it comes to working with application logging there are a few considerations for EKS. This will quickly cover the basics, the componenets, and the high level architecture for adding application logging for EKS.\nCollector The collector is most often a daemon-set living on the EKS node, or a sidecar container in the kubernetes deployment.\nThe AWS prescribed tools are:\n  Expand to see Pros and Cons of Fluent-bit   Pros: - Lightweight written in C - Plugins built for AWS (Cloudwatch, Firehose, Firelens) Cons: - Rapidly changing      Expand to see Pros and Cons of Fluentd   Pros: - Product has been around for a while, and many open source plugins Cons: - Slightly slower    AWS Recommended: Fluent-bit Aggregator (optional) This is an optional componenet often used when utilizing sidecar logging patterns to keep the sidecar resource quote low\nAWS Recommended: Fluentd Log Shipper The log shipper is the compenent, or combination of components to move logs from the cluster to the log storage location.\nUsing Fluent-Bit there are a few good options we can quickly configure\n Option 1 ships logs directly from fluent-bit to Kinesis Firehose, and then to Amazon Elasticsearch  Option 2 ships logs directly from fluent-bit to Kinesis Firehose, and then to Amazon S3 for long term retention, and lastly to Amazon Elasticsearch. This is the recommended approach when utilizing Amazon Athena to perform insights on logs.  Option 3 ships logs directly from fluent-bit to Amazon Cloudwatch Logs for long term retention, and then sets up a Cloudwatch logs subscription using Lambda to ship logs to Amazon Elasticsearch  Option 4 is a hybrid approach, and ships logs directly from fluent-bit to Cloudwatch logs for long term retention, and Kinesis Firehose to Amazon Elasticsearch.  Option 5 is another hybrid approach, and ships logs directly from fluent-bit to Kinesis Firehose which streams it to S3 for long term retention, and Amazon Elasticsearch for real time analysis.  Long Term Retention   Expand to see Pros and Cons of Elastisearch   Pros: - Fast - Good tie-ins with common logging components (Kibana/Logstash) Cons: - Expensive      Expand to see Pros and Cons of S3   Pros: - Good Ties in with Amazon Services - Low Cost Cons: - Low Performance      Expand to see Pros and Cons of Amazon Cloudwatch Logs   Pros: - Good Ties in with Amazon Services - Visual component built in - Low Cost Cons: - Difficult for navigation between log streams - Difficult search features    Visual Log Component Kibana is the visual Component when using Elastisearch for long term rentention\nAthena is the visual Component when using S3 for long term rentention\nCloudwatch is the visual Component when using Cloudwatch Logs for long term rentention\n Logging has quite a lot of options, and now that we\u0026rsquo;ve gone through all the common options, and components we will be better equiped walking through adding logging to our example application.\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/getting-started/self_paced/","title":"Self-paced Workshop","tags":[],"description":"","content":"Running the workshop on your own Only complete this section if you are running the workshop on your own. If you are at an AWS hosted event (such as re:Invent, Kubecon, Immersion Day, etc), go to Start the workshop at an AWS event.\n  Create an AWS account   "},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/devsecops/architecture/","title":"Configuring Assurance policy","tags":[],"description":"","content":"Earlier in the workshop, you deployed the Aqua platform on the Amazon EKS cluster. One of the most notable and versatile Aqua components are the Enforcers. They are deployed as a Kubernetes DaemonSet on the EKS cluster and are responsible for the auto-discovery of assets, as well as enforcement of the policies defined in the Aqua Console.\nConfigure Assurance policy in Aqua Static scanning with Aqua Aqua Platform scans all build artifacts to generate a comprehensive report describing the image layers, package versions installed, the vulnerabilities found, and fixes, if any.\nAqua scans can also track the provenance of the images and code that make up your application, and evaluate them along with the overall security posture of the application. After the scan, Aqua provides actionable security advice based on a structured decision workflow: Remediate, Mitigate, or Accept.\nAssurance policy and compliance criteria Once the images are scanned and the risk assessment is completed, you must decide whether the images are safe enough to run in production; in other words, they are in compliance. Assurance policies allow you to create a compliance gate, to make sure only clean artifacts are generated and allowed in the production environment.\nIt’s easy to create a sound assurance policy, in accordance with security best practices, by combining the various security controls provided by Aqua Platform.\nIn the Aqua Platform console, go to the Policies tab on the left and select Assurance Policies. In the screen that appears, select Default policy of type Image.\nOnce inside the policy, add the security controls indicated below.\nClick on Save to save your work.\nFor Aqua to serve as a security hook in the build pipeline, ensure the Fail Aqua step in CI/CD under Actions is checked. This causes AWS CodePipeline to fail if the image does not comply with the controls set in this policy.\nIf you choose to uncheck the Fail the Aqua step in CI/CD field, then Aqua does not fail the build, but marks the image as non-compliant.\n "},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/getting-started/aws_event/","title":"AWS event","tags":[],"description":"","content":"Running the workshop at an AWS Event Only complete this section if you are at an AWS hosted event (such as re:Invent, Kubecon, Immersion Day, or any other event hosted by an AWS employee). If you are running the workshop on your own, go to:\nStart the workshop on your own.\n  AWS Workshop Portal   "},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/configure_environment/workspace/","title":"Create a Workspace","tags":[],"description":"","content":" The Cloud9 workspace should be built by an IAM user with Administrator privileges, not the root account user. Please ensure you are logged in as an IAM user, not the root account user.\n Ad blockers, javascript disablers, and tracking blockers should be disabled for the cloud9 domain, or connecting to the workspace might be impacted. Cloud9 requires third-party-cookies. You can whitelist the specific domains.\n Launch Cloud9 in your closest region:  N. Virginia Ohio Oregon  Create a Cloud9 Environment: https://us-east-1.console.aws.amazon.com/cloud9/home?region=us-east-1\n Create a Cloud9 Environment: https://us-east-2.console.aws.amazon.com/cloud9/home?region=us-east-2\n Create a Cloud9 Environment: https://us-west-2.console.aws.amazon.com/cloud9/home?region=us-west-2\n  $(function(){$(\"#region\").tabs();});  Select Create environment Name it aqua-workshop, click Next. Choose \u0026ldquo;t3.small\u0026rdquo; for instance type, take all default values and click Create environment When it comes up, customize the environment by closing the welcome tab and opening a new terminal tab in the main work area.  Your workspace should now look like this: "},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/runtime_security/building-clusters/eksctl/","title":"Eksctl","tags":[],"description":"","content":"Eksctl When it comes to launching EKS cluster\u0026rsquo;s the first method to launch an EKS cluster is using eksctl the tool built by weaveworks.\nInstallation For linux:   Expand to see Linux Eksctl install Instructions   Download the eksctl binary:\ncurl --silent --location \u0026quot;https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz\u0026quot; | tar xz -C /tmp sudo mv -v /tmp/eksctl /usr/local/bin eksctl version    For MacOSx   Expand to see Mac OSX Eksctl install Instructions   Install via Homebrew\nbrew install eksctl eksctl version    For Windows   Expand to see Windows Eksctl install Instructions   Install via Chocolatey\nchocolatey install -y eksctl eksctl version    Bash Completion   Expand to enable Bash-completion Instructions   eksctl completion bash \u0026gt;\u0026gt; ~/.bash_completion . /etc/profile.d/bash_completion.sh . ~/.bash_completion    Eksctl Information eksctl is a command line tool which builds, launches, and controls Amazon EKS clusters for you. It uses Cloudformation, and the Kubernetes API under the hood to manage the lifecycle of events.\nThe Eksctl File eksctl can be used via the command line to launch a cluster, or use a cluster file. The cluster file is defined in yaml, and follows the cluster file eksctl schema. There are many options within the cluster spec that can configured to fit your exact need, but we are going to start off with a best practices cluster, and explain what each flag is doing.\napiVersion: eksctl.io/v1alpha5 #version of the eksctl schema kind: ClusterConfig metadata: name: robotshop # Name of the eks cluster region: us-west-2 #Region of the eks cluster iam: withOIDC: true #uses IAM for service account serviceAccounts: # Create a service account which links to the Xray policy. This later gets attached to the pod for fine grained access control - metadata: name: xray-daemon namespace: robotshop labels: {aws-usage: \u0026quot;application\u0026quot;} attachPolicyARNs: - \u0026quot;arn:aws:iam::aws:policy/AWSXRayDaemonWriteAccess\u0026quot; - metadata: name: cluster-autoscaler namespace: kube-system labels: {aws-usage: \u0026quot;cluster-ops\u0026quot;} #Here we define a new IAM policy to attach to our autoscaler service account attachPolicy: Version: \u0026quot;2012-10-17\u0026quot; Statement: - Effect: Allow Action: - \u0026quot;autoscaling:DescribeAutoScalingGroups\u0026quot; - \u0026quot;autoscaling:DescribeAutoScalingInstances\u0026quot; - \u0026quot;autoscaling:DescribeLaunchConfigurations\u0026quot; - \u0026quot;autoscaling:DescribeTags\u0026quot; - \u0026quot;autoscaling:SetDesiredCapacity\u0026quot; - \u0026quot;autoscaling:TerminateInstanceInAutoScalingGroup\u0026quot; Resource: '*' nodeGroups: - name: robotshop-ng-a tags: # EC2 tags required for cluster-autoscaler auto-discovery k8s.io/cluster-autoscaler/enabled: \u0026quot;true\u0026quot; k8s.io/cluster-autoscaler/robotshop: \u0026quot;owned\u0026quot; desiredCapacity: 1 minSize: 1 maxSize: 2 iam: withAddonPolicies: autoScaler: true externalDNS: true certManager: true ebs: true albIngress: true xRay: true cloudWatch: true availabilityZones: [\u0026quot;us-west-2a\u0026quot;] ssh: # An existing key pair for EC2 host test publicKeyName: kube volumeSize: 50 # Use the encryption key from the CLI secretsEncryption: keyARN: \u0026quot;arn:aws:kms:us-west-2:164382793440:key/751f1d85-43fd-4be4-835d-906189f64c8c\u0026quot; cloudWatch: clusterLogging: enableTypes: [\u0026quot;*\u0026quot;]    Expand to see Creation for the secretsEncryption commands   MASTER_KEY_ARN=$(aws kms create-key --query KeyMetadata.Arn --output text) aws kms create-alias \\ --alias-name alias/eks-accelerator-master-key \\ --target-key-id $(echo $MASTER_KEY_ARN | cut -d \u0026quot;/\u0026quot; -f 2) export MASTER_KEY_ARN=$MASTER_KEY_ARN echo $MASTER_KEY_ARN # Add this key arn to the eksctl file under secretsEncryption.keyARN    What does eksctl create? The eksctl command will spin up 3 cloudformation stacks using during cluster creation.\nTo learn more in depth visit the official docs: eksctl.io\n  The control plane and VPC setup for EKS   The nodegroup ASG   The service accounts and OIDC setup   Common Configuration Options for eksctl eksctl has quite a few confuration options, and we\u0026rsquo;re going to cover a few common ones before we launch our cluster.\nOptions include:\n  Existing VPC configurations   Windows Nodes   Fargate on EKS   Spot Instances   Managed Nodegroups   Launching the cluster Let\u0026rsquo;s use the cluster file we looked at earlier to launch our EKS cluster.\neksctl create cluster -f K8s/eksctl/eksctl.yaml [ℹ] eksctl version 0.21.0 [ℹ] using region us-west-2 [ℹ] setting availability zones to [us-west-2d us-west-2b us-west-2a] [ℹ] will create a CloudFormation stack for cluster itself and 1 nodegroup stack(s) [ℹ] will create a CloudFormation stack for cluster itself and 0 managed nodegroup stack(s) .... kubectl get svc # kubernetes ClusterIP 10.100.0.1 \u0026lt;none\u0026gt; 443/TCP 1m  Upgrading the eksctl control plane # To upgrade control plane to the next available version or target version eksctl upgrade cluster --name=\u0026lt;clusterName\u0026gt; eksctl upgrade cluster --name\u0026lt;clusterName\u0026gt; --version=1.16 # To update kube-proxy, run: eksctl utils update-kube-proxy #To update aws-node, run: eksctl utils update-aws-node #To update coredns, run: eksctl utils update-coredns  Upgrading the eksctl nodegroup Nodegroups can have differing versions from each other, and from the control plane in EKS. You can have a cluster on version 1.16 and a nodegroup on 1.14 and they can still function.\nTo update nodegroups in eksctl you must\n  Create New Nodegroup   Delete old Nodegroup   The pods/services/daemonsets get drained, and re-balanced through the kubernetes scheduler to keep services up and running at proper capacity.\n# Add new nodegroup with DIFFERENT name to the config file. Then create the new nodegroup, and delete the old group. #Create new group eksctl create nodegroup --config-file=K8s/eksctl/eksctl.yaml #Delete old group eksctl delete nodegroup --config-file=K8s/eksctl/eksctl.yaml --only-missing --approve  "},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/fargate/logging/application/launch_aws_services/","title":"Launching AWS Services for Logging","tags":[],"description":"","content":"Launch AWS Services For our sample application we are going to be using the fluent-bit hybrid setup shown in the last chapter.\n Fluent-bit ships logs directly to Cloudwatch logs for long term retention, and directly to Kinesis Firehose which ships to Amazon Elasticsearch. We use Kibana for log viewing. Create Elastisearch Domain aws es create-elasticsearch-domain \\ --domain-name robotshop \\ --elasticsearch-version 7.4 \\ --elasticsearch-cluster-config \\ InstanceType=m5.large.elasticsearch,InstanceCount=1 \\ --ebs-options EBSEnabled=true,VolumeType=standard,VolumeSize=100 \\ --access-policies '{\u0026quot;Version\u0026quot;:\u0026quot;2012-10-17\u0026quot;,\u0026quot;Statement\u0026quot;:[{\u0026quot;Effect\u0026quot;:\u0026quot;Allow\u0026quot;,\u0026quot;Principal\u0026quot;:{\u0026quot;AWS\u0026quot;:[\u0026quot;*\u0026quot;]},\u0026quot;Action\u0026quot;:[\u0026quot;es:*\u0026quot;],\u0026quot;Resource\u0026quot;:\u0026quot;*\u0026quot;,\u0026quot;Condition\u0026quot;:{\u0026quot;IpAddress\u0026quot;: {\u0026quot;aws:SourceIp\u0026quot;: \u0026quot;192.168.0.0/16\u0026quot;}}}]}'  You can check the status of the domain in the Elastisearch console\nYou could also check this way via AWS CLI:\naws es describe-elasticsearch-domain --domain-name robotshop-logs --query 'DomainStatus.Processing'  If the output value is false that means the domain has been processed and is now available to use.\nFeel free to move on to the next section for now.\nCreate S3 Bucket backup for Elastisearch Next let\u0026rsquo;s make a bucket to store our Elastisearch backups\naws s3 mb s3://us-west-2-robotshop-es  Create Firehose and Firehose IAM role Go to the robot-shop folder and launch the file aws/application_logging/firehose.json\nReplace the AWS s3 bucket with the bucket you created in this file BEFORE launching\naws firehose create-delivery-stream --cli-input-json file://firehose.json  Create Fluent-bit IAM policy Go to the robot-shop folder and launch the file aws/application_logging/fluent-bit-iam.json\naws iam create-policy --policy-name fluent-bit-robotshop --policy-document file://fluent-bit-iam.json  Now let\u0026rsquo;s go launch the Kubernetes resources to get the application logging working.\nCreate Fluent-bit IAM role service account We use eksctl to create an IAM service account here for the fluent-bit daemon-set. To know more about how this works check out the AWS blog\neksctl create iamserviceaccount \\ --name fluent-aws-for-fluent-bit \\ --namespace robotshop \\ --cluster robotshop \\ --attach-policy-arn arn:aws:iam::164382793440:policy/fluent-bit-robotshop \\ --approve \\ --override-existing-serviceaccounts  We can verify that came up correctly by running\nkubectl get serviceaccounts NAME SECRETS AGE default 1 2d23h fluent-aws-for-fluent-bit 1 1h  Awesome now that our AWS resources are all created let\u0026rsquo;s launch the Kubernetes resources.\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/fargate/","title":"Module 4: Secure AWS Fargate","tags":[],"description":"","content":"Chapter 7 Observability Chapter about Observability\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/devsecops/codepipeline/","title":"Integrating with AWS CodePipeline","tags":[],"description":"","content":"Create an IAM role for the AWS CodeBuild To set up AWS CodeBuild to work with the Amazon EKS cluster, you need the AWS AccountID to modify aws-auth configmap. AWS CodeBuild requires an IAM role capable of deploying to the Workload EKS cluster. You can set that up by entering these commands in succession on the AWS Cloud9 Amazon Linux machine:\n# export the AccountID as an environment variable export ACCOUNT_ID=$(aws sts get-caller-identity --output text --query Account) cd ~/environment # Create the IAM role for CodeBuild to deploy to Amazon EKS TRUST=\u0026quot;{ \\\u0026quot;Version\\\u0026quot;: \\\u0026quot;2012-10-17\\\u0026quot;, \\\u0026quot;Statement\\\u0026quot;: [ { \\\u0026quot;Effect\\\u0026quot;: \\\u0026quot;Allow\\\u0026quot;, \\\u0026quot;Principal\\\u0026quot;: { \\\u0026quot;AWS\\\u0026quot;: \\\u0026quot;arn:aws:iam::${ACCOUNT_ID}:root\\\u0026quot; }, \\\u0026quot;Action\\\u0026quot;: \\\u0026quot;sts:AssumeRole\\\u0026quot; } ] }\u0026quot; echo '{ \u0026quot;Version\u0026quot;: \u0026quot;2012-10-17\u0026quot;, \u0026quot;Statement\u0026quot;: [ { \u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;, \u0026quot;Action\u0026quot;: \u0026quot;eks:Describe*\u0026quot;, \u0026quot;Resource\u0026quot;: \u0026quot;*\u0026quot; } ] }' \u0026gt; /tmp/iam-role-policy aws iam create-role --role-name AquaWorkshopCodeBuildKubectlRole --assume-role-policy-document \u0026quot;$TRUST\u0026quot; --output text --query 'Role.Arn' aws iam put-role-policy --role-name AquaWorkshopCodeBuildKubectlRole --policy-name eks-describe --policy-document file:///tmp/iam-role-policy # Finally, modify the aws-auth configmap to map the IAM role in the kubeconfig file: ROLE=\u0026quot; - rolearn: arn:aws:iam::$ACCOUNT_ID:role/AquaWorkshopCodeBuildKubectlRole\\n username: build\\n groups:\\n - system:masters\u0026quot; kubectl get -n kube-system configmap/aws-auth -o yaml | awk \u0026quot;/mapRoles: \\|/{print;print \\\u0026quot;$ROLE\\\u0026quot;;next}1\u0026quot; \u0026gt; /tmp/aws-auth-patch.yml kubectl patch configmap/aws-auth -n kube-system --patch \u0026quot;$(cat /tmp/aws-auth-patch.yml)\u0026quot;  Fork the sample GitHub Repo We have provided a sample Go application and the AWS CloudFormation template you need for the next steps in our sample GitHub repository: https://github.com/aquasecurity/amazon-eks-devsecops. Fork this sample repository using your GitHub account, and create a GitHub access token.\nDeploy the Aqua and AWS CodePipeline integration Click the Launch button to create the CloudFormation stack in the AWS Management Console.\n   Launch template       CodePipeline \u0026amp; Aqua  Launch    Download      Enable static scanning scannercli is an Aqua binary that scans the image locally as soon as it\u0026rsquo;s built, and then communicates back to the Aqua CSP server to compare the findings with Aqua’s CyberCenter. Pertaining to the security tolerance level, the build can be passed or failed based on the scanning results. The reports are stored as an AWS CodePipeline artifact in the Amazon Simple Storage Service (Amazon S3) bucket, and can be easily retrieved from the AWS Management Console itself.\nTo enable automated static scanning of the build artifacts, scannercli is used in the buildspec.yml (https://github.com/aquasecurity/amazon-eks-devsecops/blob/master/buildspec.yml#L19) in the build stage as shown here:\nbuild: commands: - docker build --tag $REPOSITORY_URI:$TAG . - ./scannercli scan --host $AQUA_URL --user $AQUA_USER --password $AQUA_PASSWORD --local $REPOSITORY_URI:$TAG --no-verify --htmlfile aqua.html - docker push $REPOSITORY_URI:$TAG   "},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/configure_environment/k8stools/","title":"Install Kubernetes Tools","tags":[],"description":"","content":"Amazon EKS clusters require kubectl and kubelet binaries and the aws-cli or aws-iam-authenticator binary to allow IAM authentication for your Kubernetes cluster.\nIn this workshop we will give you the commands to download the Linux binaries. If you are running Mac OSX / Windows, please see the official EKS docs for the download links.\n Install kubectl sudo curl --silent --location -o /usr/local/bin/kubectl \\ https://amazon-eks.s3.us-west-2.amazonaws.com/1.17.7/2020-07-08/bin/linux/amd64/kubectl sudo chmod +x /usr/local/bin/kubectl  Update awscli Upgrade AWS CLI according to guidance in AWS documentation.\nsudo pip install --upgrade awscli \u0026amp;\u0026amp; hash -r  Install jq, envsubst (from GNU gettext utilities) and bash-completion sudo yum -y install jq gettext bash-completion moreutils  Verify the binaries are in the path and executable for command in kubectl jq aws do which $command \u0026amp;\u0026gt;/dev/null \u0026amp;\u0026amp; echo \u0026quot;$command in path\u0026quot; || echo \u0026quot;$command NOT FOUND\u0026quot; done  Enable kubectl bash_completion kubectl completion bash \u0026gt;\u0026gt; ~/.bash_completion . /etc/profile.d/bash_completion.sh . ~/.bash_completion  "},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/configure_environment/iamrole/","title":"Create an IAM role for your Workspace","tags":[],"description":"","content":" Follow this deep link to create an IAM role with Administrator access. Confirm that AWS service and EC2 are selected, then click Next to view permissions. Confirm that AdministratorAccess is checked, then click Next: Tags to assign tags. Take the defaults, and click Next: Review to review. Enter aqua-workshop-admin for the Name, and click Create role.   "},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/configure_environment/ec2instance/","title":"Attach the IAM role to your Workspace","tags":[],"description":"","content":" Follow this deep link to find your Cloud9 EC2 instance Select the instance, then choose Actions / Instance Settings / Attach/Replace IAM Role  Choose aqua-workshop-admin from the IAM Role drop down, and select Apply   "},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/devsecops/trigger_pipe/","title":"Trigger a new release","tags":[],"description":"","content":"Open CodePipeline in the Management Console. You will see a CodePipeline that starts with aqua-cicd. Click the link to view the details.\nOnce you are on the details page for the specific CodePipeline, you can see the status along with links to the Source and Build details. Click on Release Change in order to kick off a new pipeline.\nNotice the pipeline fails during the Build phase because of the Aqua scanner step with a Build error below, in the CodeBuild Phase details. Aqua scanner generates a report from the automated scan which is saved as an aqua.html artifact from the Amazon S3 instance. Aqua provides an HTML output outlining the root cause of pipeline failure based on the assurance policies you defined previously. The output also shows the various vulnerabilities, malware, and sensitive data that were detected in the image, and whether a fix is available.  "},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/configure_environment/workspaceiam/","title":"Update IAM settings for your Workspace","tags":[],"description":"","content":" Cloud9 normally manages IAM credentials dynamically. This isn\u0026rsquo;t currently compatible with the EKS IAM authentication, so we will disable it and rely on the IAM role instead.\n  Return to your workspace and click the gear icon (in top right corner), or click to open a new tab and choose \u0026ldquo;Open Preferences\u0026rdquo; Select AWS SETTINGS Turn off AWS managed temporary credentials Close the Preferences tab   To ensure temporary credentials aren\u0026rsquo;t already in place we will also remove any existing credentials file:\nrm -vf ${HOME}/.aws/credentials  We should configure our aws cli with our current region as default.\nIf you are at an AWS event, ask your instructor which AWS region to use.\n export ACCOUNT_ID=$(aws sts get-caller-identity --output text --query Account) export AWS_REGION=$(curl -s 169.254.169.254/latest/dynamic/instance-identity/document | jq -r '.region')  Check if AWS_REGION is set to desired region\ntest -n \u0026quot;$AWS_REGION\u0026quot; \u0026amp;\u0026amp; echo AWS_REGION is \u0026quot;$AWS_REGION\u0026quot; || echo AWS_REGION is not set  Let\u0026rsquo;s save these into bash_profile\necho \u0026quot;export ACCOUNT_ID=${ACCOUNT_ID}\u0026quot; | tee -a ~/.bash_profile echo \u0026quot;export AWS_REGION=${AWS_REGION}\u0026quot; | tee -a ~/.bash_profile aws configure set default.region ${AWS_REGION} aws configure get default.region  Validate the IAM role Use the GetCallerIdentity CLI command to validate that the Cloud9 IDE is using the correct IAM role.\naws sts get-caller-identity --query Arn | grep aqua-workshop-admin -q \u0026amp;\u0026amp; echo \u0026quot;IAM role valid\u0026quot; || echo \u0026quot;IAM role NOT valid\u0026quot;  If the IAM role is not valid, DO NOT PROCEED. Go back and confirm the steps on this page.\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/fargate/logging/application/launch_kube_resources/","title":"Launching Kube Resources for Logging","tags":[],"description":"","content":"Launch Kube Resources Understanding the Fluent-bit Config In the kubeneretes files we are about to launch there is a configmap with the fluent-bit configuration. If you want to edit values according to the fluent-bit documentation\nLet\u0026rsquo;s take a look at our configuration which has the Kinesis Firehose configuration\nWe add in input path from the containers log on each host, and our output is where we add in the firehose configuration from the last step.\n[SERVICE] Parsers_File /fluent-bit/parsers/parsers.conf [INPUT] Name tail Tag kube.* Path /var/log/containers/*.log DB /var/log/flb_kube.db Parser docker Docker_Mode On Mem_Buf_Limit 5MB Skip_Long_Lines On Refresh_Interval 10 [FILTER] Name kubernetes Match kube.* Kube_URL https://kubernetes.default.svc.cluster.local:443 Merge_Log On Merge_Log_Key data K8S-Logging.Parser On K8S-Logging.Exclude On [OUTPUT] Name firehose Match * region us-west-2 delivery_stream robotshop  Create Fluent-bit Resources Let\u0026rsquo;s launch our fluent-bit resources, with the daemonset using the Serviceaccount from the last step.\nspec: serviceAccountName: fluent-aws-for-fluent-bit containers: - name: aws-for-fluent-bit imagePullPolicy: IfNotPresent image: \u0026quot;amazon/aws-for-fluent-bit:2.2.0\u0026quot;  kubectl apply robot-shop/K8s/kubectl/templates/fluent-bit-clusterrole.yaml kubectl apply robot-shop/K8s/kubectl/templates/fluent-bit-clusterrolebinding.yaml kubectl apply robot-shop/K8s/kubectl/templates/fluent-bit-configmap.yaml kubectl apply robot-shop/K8s/kubectl/templates/fluent-bit-daemonset.yaml  Now lets check to see all our resources spun up correctly.\nk get daemonset -l app.kubernetes.io/name=aws-for-fluent-bit NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE fluent-aws-for-fluent-bit 3 3 3 3 3 \u0026lt;none\u0026gt; 1h  So our daemon-set up is up and running, lets go see how we check our application logs.\nGo to AWS \u0026gt; Elastisearch \u0026gt; Kibana Endpoint\nyou might need to go the access policy, and change it to let in your VPN IP address, and or use IAM based authentication.\nAWS \u0026gt; Elastisearch \u0026gt; Edit \u0026gt; Modify Acess Policy\nHow to find application logs Go to the kibana console. I\u0026rsquo;m using * as the index pattern here, but you could create indexes for larger logging clusters.\nWe apply a filter of\nkubernetes.labels.service IS web\nNow we are able to view all of our access logs from each of our microservices in one pane/view.\nThere is much more to application logging, so check out more guides and documentation, and check out the Partner chapter even more solutions.\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/runtime_security/building-clusters/terraform/","title":"Terraform","tags":[],"description":"","content":"Terraform When it comes to launching EKS cluster\u0026rsquo;s the second method to launch an EKS cluster we will go over is using terraform the tool built by hashicorp.\nInstallation For linux:   Expand to see Linux Terraform install Instructions   Download the terraform binary:\ncurl --silent --location \u0026quot;https://releases.hashicorp.com/terraform/0.12.28/terraform_0.12.28_linux_amd64.zip\u0026quot; | tar xz -C /tmp sudo mv -v /tmp/terraform /usr/local/bin terraform version    For MacOSx   Expand to see Mac OSX terraform install Instructions   Install via Homebrew\nbrew install terraform terraform version    For Windows   Expand to see Windows terraform install Instructions   Install via Chocolatey\nchocolatey install terraform terraform version    Bash Completion   Expand to enable Bash-completion Instructions   terraform -install-autocomplete    Terraform Information terraform is a popular open source Infrastructure as code tool which builds, launches, and controls resources using state.\nTerraform Information eksctl can be used via the command line to launch a cluster. The most common terraform file structure is\n  main.tf   variables.tf   outputs.tf   Terraform can get much more in depth when utilzing modules, and sub-modules but we will cover the basics to create the EKS cluster we made in the Eksctl chapter using terraform.\nTerraform main.tf In this main.tf we create\n IAM role VPC and vpc components EKS control plane EKS nodegroups  Control plane Within the file, we can change variables such as the cluster name, version, and tags. To see a complete list of options check out the eks module Docs\nNode Groups The eks module utilizes the nested worker group component to define the launch configuration used for the worker group. To see a complete list of options check out the eks module worker group Docs\nmodule \u0026quot;eks\u0026quot; { source = \u0026quot;terraform-aws-modules/eks/aws\u0026quot; cluster_name = local.cluster_name cluster_version = \u0026quot;1.16\u0026quot; subnets = module.vpc.private_subnets tags = { Environment = \u0026quot;test\u0026quot; GithubRepo = \u0026quot;terraform-aws-eks\u0026quot; GithubOrg = \u0026quot;terraform-aws-modules\u0026quot; } vpc_id = module.vpc.vpc_id worker_groups = [ { name = \u0026quot;robotshop-ng-a\u0026quot; instance_type = \u0026quot;m5.large\u0026quot; key_name = \u0026quot;kube\u0026quot; disk_size = 50 min_capacity = 1 max_capacity = 2 asg_desired_capacity = 2 additional_security_group_ids = [aws_security_group.worker_group_mgmt_one.id] } ] worker_additional_security_group_ids = [aws_security_group.all_worker_mgmt.id] }  Launching the cluster We use the example terraform cluster at K8s/terraform/main.tf\ncd K8s/terraform #initialize modules terraform init # plan the infrastructure terraform plan # deploy the infrastructure terraform apply # delete the infrastructure terraform destroy -auto-approve # terraform adds a kubeconfig to the directoy kubectl get svc --kubeconfig kubeconfig_robotshop # kubernetes ClusterIP 10.100.0.1 \u0026lt;none\u0026gt; 443/TCP 1m  Upgrading the eksctl control plane and nodegroups In terraform to upgrade the components you only need to update the main.tf  file with the new desired changes, and re-run\nterraform plan terraform apply  Upgrading un-tracked control plane components In terraform to some components are configured for you, but not included in the main.tf  such as\n  kube-proxy   aws-node (VPC cni)   coredns   To update the version of these components find the current version on the EKS Docs\nThen patch the existing objects with the newest versions.\n# kube Proxy kubectl patch daemonset kube-proxy \\ -n kube-system \\ -p '{\u0026quot;spec\u0026quot;: {\u0026quot;template\u0026quot;: {\u0026quot;spec\u0026quot;: {\u0026quot;containers\u0026quot;: [{\u0026quot;image\u0026quot;: \u0026quot;602401143452.dkr.ecr.us-west-2.amazonaws.com/eks/kube-proxy:v1.16.8\u0026quot;,\u0026quot;name\u0026quot;:\u0026quot;kube-proxy\u0026quot;}]}}}}' # aws-node (vpc CNI) kubectl apply -f https://raw.githubusercontent.com/aws/amazon-vpc-cni-k8s/release-1.6/config/v1.6/aws-k8s-cni.yaml # Coredns kubectl set image --namespace kube-system deployment.apps/coredns \\ coredns=602401143452.dkr.ecr.us-west-2.amazonaws.com/eks/coredns:v1.6.6  "},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/getting-started/aws_event/portal/","title":"AWS Workshop Portal","tags":[],"description":"","content":"Login to AWS Workshop Portal This workshop creates an AWS account and a Cloud9 environment. You will need the Participant Hash provided upon entry, and your email address to track your unique session.\nConnect to the portal by clicking the button or browsing to https://dashboard.eventengine.run/. The following screen shows up.\nEnter the provided hash in the text box. The button on the bottom right corner changes to Accept Terms \u0026amp; Login. Click on that button to continue.\nClick on AWS Console on dashboard.\nTake the defaults and click on Open AWS Console. This will open AWS Console in a new browser tab.\nOnce you have completed the step above, you can head straight to Create a Workspace\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/fargate/logging/application/partners/","title":"Application Logging with Partner Solution","tags":[],"description":"","content":"Application Logging with Partner Solution "},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/fargate/logging/_partner/","title":"Logging Partners","tags":[],"description":"","content":"Chapter 5 Partners Logging Partners Chapter about Logging Partners\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/runtime_security/building-clusters/_partner/","title":"Partners","tags":[],"description":"","content":"Partners Chapter about Building Clusters with Partner Tools\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/storage/","title":"Storage","tags":[],"description":"","content":"Chapter Storage Storage Chapter about Storage\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/registry_scanning/ecr-integration/","title":"ECR Integration","tags":[],"description":"","content":"Enable the ECR integration Enabling the integration is a quick one-step configuration. This allows you to automatically scan ECR images for vulnerabilities, check their security status and apply image assurance policies to ensure that only approved images are allowed to run.\nOnce you have added the information, click on Test Connection to verify connectivity. "},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/registry_scanning/add-image/","title":"Scanning an image","tags":[],"description":"","content":"Registering an image with Aqua Once you have successfully enabled the integration you can easily add and scan images from the registry. Aqua provides an easier way to search for the right repositories in the registry for adding images.\nIn the Aqua console, go to the Images tab and click on Add Image. As soon as you click on Add image, it will be added to the Scan queue. Select Scan Queue to check the progress of the image scan. Once the scan is completed, Aqua generates a comprehensive report of all the security risks found, and includes detailed and actionable information of the various vulnerabilities, malware, and any embedded sensitive data in the image.\nNow that the image is registered with Aqua, any subsequent pods using that image will not be blocked, and will spin up successfully.\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/security/","title":"Security","tags":[],"description":"","content":"Chapter Security Security Chapter about Security\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/","title":"CLOUD-NATIVE SECURITY WITH AQUA: AMAZON EKS","tags":[],"description":"","content":"CLOUD-NATIVE SECURITY WITH AQUA: AMAZON EKS Welcome Welcome to the Amazon EKS workshop with Aqua Security!\nObjectives Intended Audience  Developers Security/Application Teams DevOps/DevSecOps Engineers Cloud/Solutions Architects Operations Engineers Infrastructure teams  Workshop structure The workshop is structured around various aspects of cloud-native security, spanning across Build, Infrastructure and Workloads,together culminating to an overall strong security profile for your environment. It is broken down into the following sections and you should plan on 2.5 hours for completion of the course.\n Module 1: DevSecOps using AWS CodePipeline and Aqua for Amazon EKS Module 2: Securing Amazon ECR Registry with Aqua Module 3: Securing Amazon EKS workloads with Aqua runtime security Module 4: Securing workloads for Amazon EKS on Fargate using Aqua MicroEnforcer  "},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/tags/beginner/","title":"beginner","tags":[],"description":"","content":""},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/tags/cicd/","title":"cicd","tags":[],"description":"","content":""},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/tags/cloud-native/","title":"cloud-native","tags":[],"description":"","content":""},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/tags/containers/","title":"containers","tags":[],"description":"","content":""},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/tags/devops/","title":"devops","tags":[],"description":"","content":""},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/tags/devsecops/","title":"devsecops","tags":[],"description":"","content":""},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/getting-started/self_paced/eu-west-1/","title":"Ireland","tags":[],"description":"","content":"Create a Cloud9 Environment: https://eu-west-1.console.aws.amazon.com/cloud9/home?region=eu-west-1\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/configure_environment/us-east-1/","title":"N. Virginia","tags":[],"description":"","content":"Create a Cloud9 Environment: https://us-east-1.console.aws.amazon.com/cloud9/home?region=us-east-1\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/configure_environment/us-east-2/","title":"Ohio","tags":[],"description":"","content":"Create a Cloud9 Environment: https://us-east-2.console.aws.amazon.com/cloud9/home?region=us-east-2\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/getting-started/self_paced/us-east-2/","title":"Ohio","tags":[],"description":"","content":"Create a Cloud9 Environment: https://us-east-2.console.aws.amazon.com/cloud9/home?region=us-east-2\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/configure_environment/us-west-2/","title":"Oregon","tags":[],"description":"","content":"Create a Cloud9 Environment: https://us-west-2.console.aws.amazon.com/cloud9/home?region=us-west-2\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/getting-started/self_paced/us-west-2/","title":"Oregon","tags":[],"description":"","content":"Create a Cloud9 Environment: https://us-west-2.console.aws.amazon.com/cloud9/home?region=us-west-2\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/tags/security/","title":"security","tags":[],"description":"","content":""},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/getting-started/self_paced/ap-southeast-1/","title":"Singapore","tags":[],"description":"","content":"Create a Cloud9 Environment: https://ap-southeast-1.console.aws.amazon.com/cloud9/home?region=ap-southeast-1\n"},{"uri":"https://jonahjon.github.io/ps-eks-accelerator/tags/","title":"Tags","tags":[],"description":"","content":""}]